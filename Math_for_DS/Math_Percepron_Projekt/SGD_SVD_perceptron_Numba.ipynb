{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# импортируем нужные библиотеки\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "# Загрузка данных MNIST 70_000 x 784\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "y_train = y_train[:]\n",
    "y_test = y_test[:]\n",
    "# Преобразование данных в нужный формат\n",
    "X_train = X_train.reshape(60_000, 784)[:]\n",
    "X_test = X_test.reshape(10_000, 784)[:]\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "y_train_onehot = np.zeros((y_train.size, y_train.max() + 1))\n",
    "y_train_onehot[np.arange(y_train.size), y_train] = 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "# Определение параметров модели\n",
    "n_inputs = X_train.shape[1]   # Количество входных нейронов\n",
    "n_outputs = len(np.unique(y_train))  # Количество выходных нейронов\n",
    "n_hidden = 522 # np.ceil((n_inputs + n_outputs) / 2).astype(int)  # Количество нейронов в скрытом слое\n",
    "learning_rate = 0.1 # Скорость обучения\n",
    "n_epochs = 101 # количество эпох\n",
    "batch_size = 64 # количество образцов данных"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "# Определение функций активации\n",
    "@jit(nopython=True) #, fastmath=True\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# def softmax(x):\n",
    "#     exp_x = np.exp(x)\n",
    "#     return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "\n",
    "@jit(nopython=True) #, fastmath=True\n",
    "def make_dot(x,y):\n",
    "    return np.dot(x, y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "\n",
    "@jit(cache=True) #, fastmath=True\n",
    "def make_loss(y_pred, X_train, y_train):\n",
    "    loss = 0.0\n",
    "    for i in range(len(X_train)):\n",
    "        loss -= np.log(y_pred[i, y_train[i]])\n",
    "    return loss / len(X_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "\n",
    "@jit(cache=True)#(nopython=True)#(fastmath=True)\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x)\n",
    "    return exp_x / np.sum(exp_x, axis=1)[..., np.newaxis]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "\n",
    "@jit(nopython=True)#(cache=True)#(fastmath=True)\n",
    "def make_svd(hidden_weights,k):\n",
    "    U, s, V = np.linalg.svd(hidden_weights, full_matrices=False)\n",
    "    k = k  # Количество компонент для сжатия\n",
    "    S = np.diag(s[:k])\n",
    "    U = U[:, :k]\n",
    "    V = V[:k, :]\n",
    "    hidden_weights_compressed = np.dot(U, np.dot(S, V))\n",
    "    return hidden_weights_compressed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "# Инициализация весов\n",
    "weights_input_hidden = np.random.uniform(-0.5, 0.5, size=(n_inputs, n_hidden))\n",
    "bias_hidden = np.zeros(n_hidden)\n",
    "\n",
    "weights_hidden_output = np.random.uniform(-0.5, 0.5, size=(n_hidden, n_outputs))\n",
    "bias_output = np.zeros(n_outputs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Обучение модели с помощью SGD\n",
    "def train_and_predict(X_train, y_train, X_test, y_test, n_epochs, batch_size, learning_rate, weights_input_hidden=weights_input_hidden, bias_hidden=bias_hidden, weights_hidden_output=weights_hidden_output,bias_output=bias_output,k = 100):\n",
    "    for epoch in tqdm_notebook(range(n_epochs)):\n",
    "        # Перемешиваем обучающие данные\n",
    "        indices = np.random.permutation(len(X_train))\n",
    "        X_train = X_train[indices]\n",
    "        y_train = y_train[indices]\n",
    "\n",
    "        for i in range(0, len(X_train), batch_size):\n",
    "            # Получаем батч обучающих данных\n",
    "            X_batch = X_train[i:i+batch_size]\n",
    "            y_batch = y_train[i:i+batch_size]\n",
    "\n",
    "            hidden_weights = weights_input_hidden\n",
    "\n",
    "            # Применение SVD для сжатия матрицы весов скрытого слоя\n",
    "            hidden_weights_compressed = make_svd(hidden_weights, k = k)\n",
    "            U, s, V = np.linalg.svd(hidden_weights, full_matrices=False)\n",
    "            k = k  # Количество компонент для сжатия\n",
    "            S = np.diag(s[:k])\n",
    "            U = U[:, :k]\n",
    "            V = V[:k, :]\n",
    "            hidden_weights_compressed = np.dot(U, np.dot(S, V))\n",
    "\n",
    "            hidden_inputs = make_dot(X_batch, hidden_weights_compressed) + bias_hidden\n",
    "            hidden_outputs = sigmoid(hidden_inputs)\n",
    "\n",
    "            output_inputs = make_dot(hidden_outputs, weights_hidden_output) + bias_output\n",
    "            y_pred = softmax(output_inputs)\n",
    "\n",
    "            # Обратное распространение ошибки\n",
    "            error = y_pred - np.eye(n_outputs)[y_batch]\n",
    "            grad_output = error / len(X_batch)\n",
    "            grad_hidden = make_dot(grad_output, weights_hidden_output.T) * hidden_outputs * (1 - hidden_outputs)\n",
    "\n",
    "            output_inputs = make_dot(hidden_outputs, weights_hidden_output) + bias_output\n",
    "            y_pred = softmax(output_inputs)\n",
    "\n",
    "            # Обновление весов и пороговых значений\n",
    "            weights_hidden_output -= learning_rate * make_dot(hidden_outputs.T, grad_output)\n",
    "            bias_output -= learning_rate * np.sum(grad_output, axis=0)\n",
    "\n",
    "            weights_input_hidden -= learning_rate * make_dot(X_batch.T, grad_hidden)\n",
    "            bias_hidden -= learning_rate * np.sum(grad_hidden, axis=0)\n",
    "\n",
    "        # Вычисление функции потерь на обучающих и тестовых данных\n",
    "        hidden_train = make_dot(X_train, weights_input_hidden) + bias_hidden\n",
    "        hidden_train = sigmoid(hidden_train)\n",
    "\n",
    "        output_train = make_dot(hidden_train, weights_hidden_output) + bias_output\n",
    "        y_pred_train = softmax(output_train)\n",
    "        train_loss = np.mean(-np.log(y_pred_train[np.arange(len(X_train)), y_train]))\n",
    "\n",
    "        hidden_test = make_dot(X_test, weights_input_hidden) + bias_hidden\n",
    "        hidden_test = sigmoid(hidden_test)\n",
    "\n",
    "        output_test = make_dot(hidden_test, weights_hidden_output) + bias_output\n",
    "        y_pred_test = softmax(output_test)\n",
    "        test_loss = np.mean(-np.log(y_pred_test[np.arange(len(X_test)), y_test]))\n",
    "\n",
    "        # Выводим значение функции потерь на каждой эпохе\n",
    "        if epoch % 50 == 0:\n",
    "            print(f\"Epoch {epoch}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "    # Предсказание классов для новых данных\n",
    "    hidden_inputs = make_dot(X_test, weights_input_hidden) + bias_hidden\n",
    "    hidden_outputs = sigmoid(hidden_inputs)\n",
    "\n",
    "    output_inputs = make_dot(hidden_outputs, weights_hidden_output) + bias_output\n",
    "    y_pred = np.argmax(output_inputs, axis=1)\n",
    "\n",
    "    # Вычисление точности модели на тестовых данных\n",
    "    accuracy = np.mean(y_pred == y_test)\n",
    "\n",
    "    return weights_input_hidden, bias_hidden, weights_hidden_output, bias_output, y_pred, accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/801 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9b0033143bf74b87830afc87d40d5ec9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train Loss: 0.1128, Test Loss: 0.1465\n",
      "Epoch 50, Train Loss: 0.0173, Test Loss: 0.0861\n",
      "Epoch 100, Train Loss: 0.0086, Test Loss: 0.0832\n",
      "Epoch 150, Train Loss: 0.0059, Test Loss: 0.0827\n",
      "Epoch 200, Train Loss: 0.0045, Test Loss: 0.0826\n",
      "Epoch 250, Train Loss: 0.0036, Test Loss: 0.0824\n",
      "Epoch 300, Train Loss: 0.0031, Test Loss: 0.0831\n",
      "Epoch 350, Train Loss: 0.0027, Test Loss: 0.0832\n",
      "Epoch 400, Train Loss: 0.0025, Test Loss: 0.0840\n",
      "Epoch 450, Train Loss: 0.0022, Test Loss: 0.0843\n",
      "Epoch 500, Train Loss: 0.0020, Test Loss: 0.0844\n",
      "Epoch 550, Train Loss: 0.0018, Test Loss: 0.0846\n",
      "Epoch 600, Train Loss: 0.0016, Test Loss: 0.0850\n",
      "Epoch 650, Train Loss: 0.0015, Test Loss: 0.0849\n",
      "Epoch 700, Train Loss: 0.0014, Test Loss: 0.0853\n",
      "Epoch 750, Train Loss: 0.0013, Test Loss: 0.0854\n",
      "Epoch 800, Train Loss: 0.0013, Test Loss: 0.0859\n",
      "Accuracy: 0.9797\n"
     ]
    }
   ],
   "source": [
    "weights_input_hidden, bias_hidden, weights_hidden_output, bias_output, y_pred, accuracy = train_and_predict(X_train, y_train, X_test, y_test, n_epochs=801, batch_size=64, learning_rate=0.1, k=400)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# no SVD n_epochs = 501 Accuracy: 0.828\n",
    "# k = 50 n_epochs = 500 Accuracy: 0.85\n",
    "# k = 100  n_epochs = 1501 n_hidden = 522 Accuracy: 0.866\n",
    "# k = 250 n_epochs = 500 Accuracy: 0.85\n",
    "# 100/100 [03:09<00:00, 11.01it/s] y_train = y_train[:1200] n_epochs = 100 к=100 Accuracy: 0.817\n",
    "# 100/100 [03:09<00:00, 11.01it/s] y_train = y_train[:1200] n_epochs = 100 к=100 Accuracy: 0.833\n",
    "# 100/100 [03:24<00:00, 11.01it/s] y_train = y_train[:1200] n_epochs = 100 к=300 Accuracy: 0.8791\n",
    "# 100/100 [43:04<00:00, 11.01it/s] y_train = y_train[:16_000] n_epochs = 100 к=300 Accuracy: 0.94075\n",
    "# 300/300 [01:03:04<00:00, 11.01it/s] y_train = y_train[:16_000] n_epochs = 300 к=300 Accuracy:  0.94175\n",
    "# 500/500 [39:28<00:00, 11.01it/s] y_train = y_train[:6_000] n_epochs = 500 к=400 Accuracy: 0.9455\n",
    "# 800/800 [39:28<00:00, 11.01it/s] y_train = y_train[:6_000] n_epochs = 800 к=400 Accuracy: 0.945\n",
    "# 500/500 [05:33:28<00:00, 11.01it/s] y_train = y_train[:12_000] n_epochs = 500 к=400 Accuracy: 0.938\n",
    "# 800/800 [10:17:16<00:00, 46.01it/s] y_train = y_train[:] n_epochs = 800 к=400 Accuracy: 0.9797"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3458333333333333\n"
     ]
    }
   ],
   "source": [
    "# Предсказание классов для новых данных\n",
    "hidden_inputs = np.dot(X_test, weights_input_hidden) + bias_hidden\n",
    "hidden_outputs = sigmoid(hidden_inputs)\n",
    "\n",
    "output_inputs = np.dot(hidden_outputs, weights_hidden_output) + bias_output\n",
    "y_pred = np.argmax(output_inputs, axis=1)\n",
    "\n",
    "# Вычисление точности модели на тестовых данных\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "no SVD\n",
    "# Определение параметров модели\n",
    "n_inputs = X_train.shape[1]   # Количество входных нейронов\n",
    "n_outputs = len(np.unique(y_train))  # Количество выходных нейронов\n",
    "n_hidden = 522 # np.ceil((n_inputs + n_outputs) / 2).astype(int)  # Количество нейронов в скрытом слое\n",
    "learning_rate = 0.1 # Скорость обучения\n",
    "n_epochs = 1501 # количество эпох\n",
    "batch_size = 32 # количество образцов данных\n",
    "# Epoch 0, Train Loss: 0.9151, Test Loss: 1.0985\n",
    "# Epoch 50, Train Loss: 0.0337, Test Loss: 0.4167\n",
    "# Epoch 100, Train Loss: 0.0149, Test Loss: 0.4140\n",
    "# Epoch 150, Train Loss: 0.0093, Test Loss: 0.4194\n",
    "# Epoch 200, Train Loss: 0.0068, Test Loss: 0.4231\n",
    "# Epoch 250, Train Loss: 0.0053, Test Loss: 0.4270\n",
    "# Epoch 300, Train Loss: 0.0043, Test Loss: 0.4316\n",
    "# Epoch 350, Train Loss: 0.0036, Test Loss: 0.4348\n",
    "# Epoch 400, Train Loss: 0.0031, Test Loss: 0.4377\n",
    "# Epoch 450, Train Loss: 0.0027, Test Loss: 0.4411\n",
    "# Epoch 500, Train Loss: 0.0024, Test Loss: 0.4437\n",
    "# Epoch 550, Train Loss: 0.0022, Test Loss: 0.4460\n",
    "# Epoch 600, Train Loss: 0.0020, Test Loss: 0.4486\n",
    "# Epoch 650, Train Loss: 0.0018, Test Loss: 0.4506\n",
    "# Epoch 700, Train Loss: 0.0017, Test Loss: 0.4527\n",
    "# Epoch 750, Train Loss: 0.0016, Test Loss: 0.4546\n",
    "# Epoch 800, Train Loss: 0.0014, Test Loss: 0.4564\n",
    "# Epoch 850, Train Loss: 0.0014, Test Loss: 0.4582\n",
    "# Epoch 900, Train Loss: 0.0013, Test Loss: 0.4598\n",
    "# Epoch 950, Train Loss: 0.0012, Test Loss: 0.4613\n",
    "# Epoch 1000, Train Loss: 0.0011, Test Loss: 0.4629\n",
    "# Epoch 1050, Train Loss: 0.0011, Test Loss: 0.4642\n",
    "# Epoch 1100, Train Loss: 0.0010, Test Loss: 0.4657\n",
    "# Epoch 1150, Train Loss: 0.0010, Test Loss: 0.4670\n",
    "# Epoch 1200, Train Loss: 0.0009, Test Loss: 0.4683\n",
    "# Epoch 1250, Train Loss: 0.0009, Test Loss: 0.4695\n",
    "# Epoch 1300, Train Loss: 0.0008, Test Loss: 0.4707\n",
    "# Epoch 1350, Train Loss: 0.0008, Test Loss: 0.4719\n",
    "# Epoch 1400, Train Loss: 0.0008, Test Loss: 0.4730\n",
    "# Epoch 1450, Train Loss: 0.0007, Test Loss: 0.4741\n",
    "# Epoch 1500, Train Loss: 0.0007, Test Loss: 0.4751\n",
    "Wall time: 4min 42s\n",
    "\n",
    "Accuracy: 0.84"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "SVD On\n",
    "k = 100  # Количество компонент для сжатия\n",
    "# Определение параметров модели\n",
    "n_inputs = X_train.shape[1]   # Количество входных нейронов\n",
    "n_outputs = len(np.unique(y_train))  # Количество выходных нейронов\n",
    "n_hidden = 522 # np.ceil((n_inputs + n_outputs) / 2).astype(int)  # Количество нейронов в скрытом слое\n",
    "learning_rate = 0.1 # Скорость обучения\n",
    "n_epochs = 1501 # количество эпох\n",
    "batch_size = 32 # количество образцов данных\n",
    "# Epoch 0, Train Loss: 1.3839, Test Loss: 1.6510\n",
    "# Epoch 50, Train Loss: 0.3226, Test Loss: 0.7049\n",
    "# Epoch 100, Train Loss: 0.2353, Test Loss: 0.6711\n",
    "# Epoch 150, Train Loss: 0.2131, Test Loss: 0.6851\n",
    "# Epoch 200, Train Loss: 0.1888, Test Loss: 0.6803\n",
    "# Epoch 250, Train Loss: 0.1727, Test Loss: 0.6811\n",
    "# Epoch 300, Train Loss: 0.1571, Test Loss: 0.6768\n",
    "# Epoch 350, Train Loss: 0.1501, Test Loss: 0.6812\n",
    "# Epoch 400, Train Loss: 0.1416, Test Loss: 0.6817\n",
    "# Epoch 450, Train Loss: 0.1347, Test Loss: 0.6821\n",
    "# Epoch 500, Train Loss: 0.1288, Test Loss: 0.6831\n",
    "# Epoch 550, Train Loss: 0.1237, Test Loss: 0.6840\n",
    "# Epoch 600, Train Loss: 0.1188, Test Loss: 0.6846\n",
    "# Epoch 650, Train Loss: 0.1142, Test Loss: 0.6848\n",
    "# Epoch 700, Train Loss: 0.1103, Test Loss: 0.6851\n",
    "# Epoch 750, Train Loss: 0.1073, Test Loss: 0.6868\n",
    "# Epoch 800, Train Loss: 0.1050, Test Loss: 0.6888\n",
    "# Epoch 850, Train Loss: 0.1026, Test Loss: 0.6901\n",
    "# Epoch 900, Train Loss: 0.0997, Test Loss: 0.6905\n",
    "# Epoch 950, Train Loss: 0.0974, Test Loss: 0.6917\n",
    "# Epoch 1000, Train Loss: 0.0954, Test Loss: 0.6928\n",
    "# Epoch 1050, Train Loss: 0.0934, Test Loss: 0.6936\n",
    "# Epoch 1100, Train Loss: 0.0917, Test Loss: 0.6948\n",
    "# Epoch 1150, Train Loss: 0.0899, Test Loss: 0.6958\n",
    "# Epoch 1200, Train Loss: 0.0881, Test Loss: 0.6963\n",
    "# Epoch 1250, Train Loss: 0.0868, Test Loss: 0.6973\n",
    "# Epoch 1300, Train Loss: 0.0854, Test Loss: 0.6983\n",
    "# Epoch 1350, Train Loss: 0.0839, Test Loss: 0.6990\n",
    "# Epoch 1400, Train Loss: 0.0829, Test Loss: 0.7002\n",
    "# Epoch 1450, Train Loss: 0.0815, Test Loss: 0.7008\n",
    "# Epoch 1500, Train Loss: 0.0807, Test Loss: 0.7021\n",
    "Wall time: 57min 34s\n",
    "Accuracy: 0.866"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "k = 250\n",
    "\n",
    "# Epoch 0, Train Loss: 1.0804, Test Loss: 1.3565\n",
    "# Epoch 50, Train Loss: 0.0981, Test Loss: 0.5274\n",
    "# Epoch 100, Train Loss: 0.0671, Test Loss: 0.5420\n",
    "# Epoch 150, Train Loss: 0.0480, Test Loss: 0.5320\n",
    "# Epoch 200, Train Loss: 0.0401, Test Loss: 0.5353\n",
    "# Epoch 250, Train Loss: 0.0348, Test Loss: 0.5368\n",
    "# Epoch 300, Train Loss: 0.0303, Test Loss: 0.5361\n",
    "# Epoch 350, Train Loss: 0.0275, Test Loss: 0.5384\n",
    "# Epoch 400, Train Loss: 0.0255, Test Loss: 0.5405\n",
    "# Epoch 450, Train Loss: 0.0236, Test Loss: 0.5421\n",
    "# Epoch 500, Train Loss: 0.0219, Test Loss: 0.5425\n",
    "# Wall time: 18min 48s\n",
    "\n",
    "Accuracy: 0.85"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "k = 50  # Количество компонент для сжатия\n",
    "\n",
    "Epoch 0, Train Loss: 1.3601, Test Loss: 1.6002\n",
    "Epoch 50, Train Loss: 0.7355, Test Loss: 1.2752\n",
    "Epoch 100, Train Loss: 0.4583, Test Loss: 1.0451\n",
    "Epoch 150, Train Loss: 0.3726, Test Loss: 0.9839\n",
    "Epoch 200, Train Loss: 0.3426, Test Loss: 0.9751\n",
    "Epoch 250, Train Loss: 0.2963, Test Loss: 0.9399\n",
    "Epoch 300, Train Loss: 0.2588, Test Loss: 0.9129\n",
    "Epoch 350, Train Loss: 0.1831, Test Loss: 0.8367\n",
    "Epoch 400, Train Loss: 0.1484, Test Loss: 0.8013\n",
    "Epoch 450, Train Loss: 0.1218, Test Loss: 0.7711\n",
    "Epoch 500, Train Loss: 0.1040, Test Loss: 0.7506\n",
    "Wall time: 18min 57s\n",
    "\n",
    "Accuracy: 0.828"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "  k = 500  # Количество компонент для сжатия\n",
    "y_train = y_train[:5500]\n",
    "y_test = y_test[:1000]\n",
    "Epoch 0, Train Loss: 0.9050, Test Loss: 1.1975\n",
    "Epoch 50, Train Loss: 0.0332, Test Loss: 0.3967\n",
    "Epoch 100, Train Loss: 0.0152, Test Loss: 0.3999\n",
    "Epoch 150, Train Loss: 0.0095, Test Loss: 0.4015\n",
    "Epoch 200, Train Loss: 0.0069, Test Loss: 0.4068\n",
    "Epoch 250, Train Loss: 0.0054, Test Loss: 0.4102\n",
    "Epoch 300, Train Loss: 0.0044, Test Loss: 0.4133\n",
    "Epoch 350, Train Loss: 0.0038, Test Loss: 0.4170\n",
    "Epoch 400, Train Loss: 0.0032, Test Loss: 0.4196\n",
    "Epoch 450, Train Loss: 0.0028, Test Loss: 0.4227\n",
    "Epoch 500, Train Loss: 0.0025, Test Loss: 0.4248\n",
    "CPU times: user 2h 26min 39s, sys: 33min 17s, total: 2h 59min 56s\n",
    "Wall time: 1h 43min 21s\n",
    "Accuracy: 0.894"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_train = y_train[:1500]\n",
    "y_test = y_test[:500]\n",
    "# Преобразование данных в нужный формат\n",
    "X_train = X_train.reshape(60_000, 784)[:1500]\n",
    "X_test = X_test.reshape(10_000, 784)[:500]\n",
    "n_hidden = 522 # np.ceil((n_inputs + n_outputs) / 2).astype(int)  # Количество нейронов в скрытом слое\n",
    "learning_rate = 0.1 # Скорость обучения\n",
    "n_epochs = 501 # количество эпох\n",
    "batch_size = 32 # количество образцов данных\n",
    "k = 250  # Количество компонент для сжатия\n",
    "Epoch 0, Train Loss: 1.0307, Test Loss: 1.1796\n",
    "Epoch 50, Train Loss: 0.0986, Test Loss: 0.4407\n",
    "Epoch 100, Train Loss: 0.0535, Test Loss: 0.4412\n",
    "Epoch 150, Train Loss: 0.0382, Test Loss: 0.4425\n",
    "Epoch 200, Train Loss: 0.0314, Test Loss: 0.4499\n",
    "Epoch 250, Train Loss: 0.0259, Test Loss: 0.4532\n",
    "Epoch 300, Train Loss: 0.0236, Test Loss: 0.4608\n",
    "Epoch 350, Train Loss: 0.0207, Test Loss: 0.4633\n",
    "Epoch 400, Train Loss: 0.0190, Test Loss: 0.4681\n",
    "Epoch 450, Train Loss: 0.0178, Test Loss: 0.4714\n",
    "Epoch 500, Train Loss: 0.0163, Test Loss: 0.4744\n",
    "CPU times: user 4h 14min 39s, sys: 1h 34min 55s, total: 5h 49min 34s\n",
    "Wall time: 1h 29min 56s\n",
    "Accuracy: 0.886"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    " k = 250  # Количество компонент для сжатия\n",
    "y_train = y_train[:2500]\n",
    "y_test = y_test[:1000]\n",
    "# Преобразование данных в нужный формат\n",
    "X_train = X_train.reshape(60_000, 784)[:2500]\n",
    "X_test = X_test.reshape(10_000, 784)[:1000]\n",
    "Epoch 0, Train Loss: 1.6045, Test Loss: 1.9372\n",
    "Epoch 50, Train Loss: 0.0835, Test Loss: 0.4695\n",
    "Epoch 100, Train Loss: 0.0468, Test Loss: 0.4685\n",
    "Epoch 150, Train Loss: 0.0370, Test Loss: 0.4827\n",
    "Epoch 200, Train Loss: 0.0265, Test Loss: 0.4807\n",
    "Epoch 250, Train Loss: 0.0233, Test Loss: 0.4863\n",
    "Epoch 300, Train Loss: 0.0207, Test Loss: 0.4917\n",
    "Epoch 350, Train Loss: 0.0182, Test Loss: 0.4947\n",
    "Epoch 400, Train Loss: 0.0166, Test Loss: 0.4968\n",
    "Epoch 450, Train Loss: 0.0151, Test Loss: 0.5000\n",
    "Epoch 500, Train Loss: 0.0143, Test Loss: 0.5036\n",
    "CPU times: user 3h 48min 47s, sys: 56min 33s, total: 4h 45min 20s\n",
    "Wall time: 2h 44min 52s\n",
    "Accuracy: 0.871"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_train = y_train[:2500]\n",
    "y_test = y_test[:500]\n",
    "# Преобразование данных в нужный формат\n",
    "X_train = X_train.reshape(60_000, 784)[:2500]\n",
    "X_test = X_test.reshape(10_000, 784)[:500]\n",
    "k = 550  # Количество компонент для сжатия\n",
    "\n",
    "Epoch 0, Train Loss: 0.9871, Test Loss: 1.2458\n",
    "Epoch 50, Train Loss: 0.0352, Test Loss: 0.3426\n",
    "Epoch 100, Train Loss: 0.0124, Test Loss: 0.3376\n",
    "Epoch 150, Train Loss: 0.0078, Test Loss: 0.3440\n",
    "Epoch 200, Train Loss: 0.0056, Test Loss: 0.3446\n",
    "Epoch 250, Train Loss: 0.0043, Test Loss: 0.3512\n",
    "Epoch 300, Train Loss: 0.0035, Test Loss: 0.3525\n",
    "Epoch 350, Train Loss: 0.0029, Test Loss: 0.3538\n",
    "Epoch 400, Train Loss: 0.0025, Test Loss: 0.3561\n",
    "Epoch 450, Train Loss: 0.0022, Test Loss: 0.3572\n",
    "Epoch 500, Train Loss: 0.0019, Test Loss: 0.3612\n",
    "CPU times: user 7h 26min 40s, sys: 2h 38min 41s, total: 10h 5min 21s\n",
    "Wall time: 2h 35min 33s\n",
    "\n",
    "\n",
    "Accuracy: 0.896"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}