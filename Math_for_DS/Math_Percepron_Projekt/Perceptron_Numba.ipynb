{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm_notebook"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numba in c:\\users\\rost\\anaconda3\\lib\\site-packages (0.56.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\rost\\anaconda3\\lib\\site-packages (from numba) (67.3.1)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in c:\\users\\rost\\anaconda3\\lib\\site-packages (from numba) (0.39.1)\n",
      "Requirement already satisfied: numpy<1.24,>=1.18 in c:\\users\\rost\\anaconda3\\lib\\site-packages (from numba) (1.23.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\rost\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\rost\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\rost\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\rost\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\rost\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\rost\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install numba"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from numba import jit"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "# Загрузка данных MNIST\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "y_train = y_train[:16_000]\n",
    "y_test = y_test[:4_000]\n",
    "\n",
    "# Преобразование данных в нужный формат\n",
    "X_train = X_train.reshape(60_000, 784)[:16_000]\n",
    "X_test = X_test.reshape(10_000, 784)[:4_000]\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "y_train_onehot = np.zeros((y_train.size, y_train.max() + 1))\n",
    "y_train_onehot[np.arange(y_train.size), y_train] = 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "# Определим параметры модели\n",
    "n_inputs = X_train.shape[1] # Количество входных нейронов\n",
    "n_hidden = 522  # Количество нейронов в скрытом слое\n",
    "n_outputs = len(np.unique(y_train))  # Количество выходных нейронов\n",
    "learning_rate = 0.1\n",
    "n_epochs = 1001\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "# Инициализация весов\n",
    "weights_input_hidden = np.random.uniform(-0.5, 0.5, size=(n_inputs, n_hidden))\n",
    "bias_hidden = np.zeros(n_hidden)\n",
    "\n",
    "weights_hidden_output = np.random.uniform(-0.5, 0.5, size=(n_hidden, n_outputs))\n",
    "bias_output = np.zeros(n_outputs)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "# Определение функций активации.\n",
    "@jit(nopython=True, fastmath=True)\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "@jit(nopython=True, fastmath=True)\n",
    "def make_dot(x,y):\n",
    "    return np.dot(x, y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "\n",
    "@jit(cache=True, fastmath=True)\n",
    "def make_loss(y_pred, X_train, y_train):\n",
    "    loss = 0.0\n",
    "    for i in range(len(X_train)):\n",
    "        loss -= np.log(y_pred[i, y_train[i]])\n",
    "    return loss / len(X_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "\n",
    "@jit(cache=True)#(nopython=True)#(fastmath=True)\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x)\n",
    "    return exp_x / np.sum(exp_x, axis=1)[..., np.newaxis] #exp_x / np.sum(exp_x, axis=1, keepdims=True) #\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# @jit(nopython=True)\n",
    "def perceptron_train(X_train, y_train, weights_input_hidden, bias_hidden, weights_hidden_output, bias_output, n_epochs, learning_rate, n_outputs):\n",
    "    for epoch in tqdm_notebook(range(n_epochs)):\n",
    "        # Forward pass\n",
    "        hidden_inputs = make_dot(X_train, weights_input_hidden) + bias_hidden\n",
    "        hidden_outputs = sigmoid(hidden_inputs)\n",
    "        output_inputs = make_dot(hidden_outputs, weights_hidden_output) + bias_output\n",
    "        y_pred = softmax(output_inputs)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = make_loss(y_pred,X_train,y_train)#-np.sum(np.log(y_pred[np.arange(len(X_train)), y_train])) / len(X_train)\n",
    "\n",
    "        # Compute gradients\n",
    "        dL_dOutputInputs = y_pred\n",
    "        dL_dOutputInputs[np.arange(len(X_train)), y_train] -= 1\n",
    "        dL_dOutputInputs /= len(X_train)\n",
    "\n",
    "        dL_dWeightsHiddenOutput = make_dot(hidden_outputs.T, dL_dOutputInputs)\n",
    "        dbiasOutput = np.sum(dL_dOutputInputs, axis=0)\n",
    "\n",
    "        dL_dHiddenInputs = make_dot(dL_dOutputInputs, weights_hidden_output.T) * sigmoid(hidden_inputs)\n",
    "        dL_dWeightsInputHidden = make_dot(X_train.T, dL_dHiddenInputs)\n",
    "        dbiasHidden = np.sum(dL_dHiddenInputs, axis=0)\n",
    "\n",
    "        # Update weights and biases\n",
    "        weights_hidden_output -= learning_rate * dL_dWeightsHiddenOutput\n",
    "        bias_output -= learning_rate * dbiasOutput\n",
    "        weights_input_hidden -= learning_rate * dL_dWeightsInputHidden\n",
    "        bias_hidden -= learning_rate * dbiasHidden\n",
    "\n",
    "    return weights_input_hidden, bias_hidden, weights_hidden_output, bias_output\n",
    "\n",
    "\n",
    "# [00:57<00:00, 14.52it/s] y_train = y_train[:6000] n_epochs = 500 Accuracy: 0.853\n",
    "# [04:39<00:00, 11.01it/s] y_train = y_train[:16000] n_epochs = 1000 Accuracy: 0.8725\n",
    "\n",
    "# 5/5  y_train = y_train[:] n_epochs = 5 Accuracy: 0.9098\n",
    "# 500/500 [00:16<00:00, 15.01it/s] y_train = y_train[:1000] n_epochs = 500 Accuracy: 0.84\n",
    "# 500/500 [00:42<00:00, 12.261it/s] y_train = y_train[:6000] n_epochs = 500 Accuracy: 0.912\n",
    "# 1500/1500 [02:07<00:00, 11.01it/s] y_train = y_train[:6000] n_epochs = 1500 Accuracy: 0.879\n",
    "# 1000/1000 [03:37<00:00, 11.01it/s] y_train = y_train[:16000] n_epochs = 1000 Accuracy: 0.87\n",
    "# 1000/1000 [14:24<00:00, 11.01it/s] y_train = y_train[:] n_epochs = 1000 Accuracy: 0.9096"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1001 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "995c26bc17874670b9415a23828cd330"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weights_input_hidden, bias_hidden, weights_hidden_output, bias_output = perceptron_train(X_train, y_train, weights_input_hidden, bias_hidden, weights_hidden_output, bias_output, n_epochs, learning_rate, n_outputs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "hidden_inputs = np.dot(X_test, weights_input_hidden) + bias_hidden\n",
    "hidden_outputs = sigmoid(hidden_inputs)\n",
    "\n",
    "output_inputs = np.dot(hidden_outputs, weights_hidden_output) + bias_output\n",
    "y_pred = np.argmax(output_inputs, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8725\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(f'Accuracy: {accuracy}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}